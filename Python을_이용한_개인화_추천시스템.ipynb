{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python을 이용한 개인화 추천시스템.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-dYTBPWHCFV8",
        "wJIyF1eUHsGX",
        "pJFCWmfOomm2",
        "G9YYInM6ZNRG",
        "5gcwdMsCev1I",
        "Y2rLnKPveXm5",
        "oMb6kv1NhPlB",
        "pnXoAItQmQS_",
        "CWhLhYimpsig",
        "xTgHWIAIuWhA",
        "9jd2ZT-Qzyf2",
        "cXKUhJ860CAc",
        "3U_1HX9T6qOy",
        "1s2iSiTENUrF",
        "M7HIuUIWFLV9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dYTBPWHCFV8"
      },
      "source": [
        "### 제 2장 기본적인 추천 시스템"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gEE9Z8X8MLY",
        "outputId": "9887ed23-0fe6-430e-d400-3f88a381d7a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "x2OhFCEyDxRa",
        "outputId": "46616cbd-7e7f-4f08-8300-c7e36d0376df"
      },
      "source": [
        "import pandas as pd\n",
        "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
        "users = users.set_index('user_id')\n",
        "users.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip_code</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>85711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>53</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>94043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>32067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>43537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>15213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         age sex  occupation zip_code\n",
              "user_id                              \n",
              "1         24   M  technician    85711\n",
              "2         53   F       other    94043\n",
              "3         23   M      writer    32067\n",
              "4         24   M  technician    43537\n",
              "5         33   F       other    15213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "uD-mJwIRAB7F",
        "outputId": "4173445d-0c1e-470a-dfdc-9e870a3edbe5"
      },
      "source": [
        "# u.item 파일을 DataFrame으로 읽기\n",
        "# 장르:unknown~Western (장르 동시에 체크 된 경우 존재.)\n",
        "import pandas as pd\n",
        "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', \n",
        "          'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', \n",
        "          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n",
        "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "movies = pd.read_csv('/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
        "movies = movies.set_index('movie_id')\n",
        "movies.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>release date</th>\n",
              "      <th>video release date</th>\n",
              "      <th>IMDB URL</th>\n",
              "      <th>unknown</th>\n",
              "      <th>Action</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Children's</th>\n",
              "      <th>Comedy</th>\n",
              "      <th>Crime</th>\n",
              "      <th>Documentary</th>\n",
              "      <th>Drama</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>Film-Noir</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Musical</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Sci-Fi</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movie_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      title release date  ...  War Western\n",
              "movie_id                                  ...             \n",
              "1          Toy Story (1995)  01-Jan-1995  ...    0       0\n",
              "2          GoldenEye (1995)  01-Jan-1995  ...    0       0\n",
              "3         Four Rooms (1995)  01-Jan-1995  ...    0       0\n",
              "4         Get Shorty (1995)  01-Jan-1995  ...    0       0\n",
              "5            Copycat (1995)  01-Jan-1995  ...    0       0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "9NBzHi2GAB9l",
        "outputId": "f2a63b44-dd75-4ed3-e241-e8ea907247ca"
      },
      "source": [
        "# u.data 파일을 DataFrame으로 읽기\n",
        "import pandas as pd\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/u.data', sep='\\t', names=r_cols, encoding='latin-1') \n",
        "ratings = ratings.set_index('user_id')\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         movie_id  rating  timestamp\n",
              "user_id                             \n",
              "196           242       3  881250949\n",
              "186           302       3  891717742\n",
              "22            377       1  878887116\n",
              "244            51       2  880606923\n",
              "166           346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hC0U0FaACCO"
      },
      "source": [
        "# Best-seller 추천 (가장 인기 있는 제품 추천)\n",
        "def recom_movie1(n_items):\n",
        "    movie_sort = movie_mean.sort_values(ascending=False)[:n_items]\n",
        "    recom_movies = movies.loc[movie_sort.index]\n",
        "    recommendations = recom_movies['title']\n",
        "    return recommendations\n",
        "\n",
        "# def recom_movie2(n_items): 위에 있는 함수와 동일.\n",
        "# return movies.loc[movie_mean.sort_values(ascending=False)[:n_items].index]['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYz9EiDLACJE",
        "outputId": "b58f9dde-ef64-451e-bef1-69dfa0159807"
      },
      "source": [
        "# 평점의 평균값이 가장 높은 것을 순서대로 5개 추천.\n",
        "movie_mean = ratings.groupby(['movie_id'])['rating'].mean()\n",
        "recom_movie1(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "movie_id\n",
              "1293                                      Star Kid (1997)\n",
              "1467                 Saint of Fort Washington, The (1993)\n",
              "1653    Entertaining Angels: The Dorothy Day Story (1996)\n",
              "814                         Great Day in Harlem, A (1994)\n",
              "1122                       They Made Me a Criminal (1939)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkVKSuFOACNN"
      },
      "source": [
        "# 정확도 계산 (정확도 지표 RMSE 선택.)\n",
        "import numpy as np\n",
        "def RMSE(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udW-Y-bHJorm",
        "outputId": "91b28841-7210-4e2f-d9a8-b67e986f259d"
      },
      "source": [
        "rmse = []\n",
        "for user in set(ratings.index): # index로 지정했던 user_id 사용.\n",
        "    y_true = ratings.loc[user]['rating']\n",
        "    y_pred = movie_mean[ratings.loc[user]['movie_id']] # 평점평균: 예측값\n",
        "    accuracy = RMSE(y_true, y_pred)\n",
        "    rmse.append(accuracy) # 현재 사용자의 RMSE\n",
        "print(np.mean(rmse)) # 전체 사용자의 RMSE의 평균"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.996007224010567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JI9QY7LJoui"
      },
      "source": [
        "# 사용자 집단별 추천\n",
        "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
        "\n",
        "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', 'unknown', \n",
        "          'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', \n",
        "          'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', \n",
        "          'Thriller', 'War', 'Western']\n",
        "movies = pd.read_csv('/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
        "\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/u.data', sep='\\t', names=r_cols, encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UK3_mn7Jo-J"
      },
      "source": [
        "# timestamp 제거 \n",
        "ratings = ratings.drop('timestamp', axis=1)\n",
        "\n",
        "# movie ID와 title 빼고 다른 데이터 제거\n",
        "movies = movies[['movie_id', 'title']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1ZdfPmIL-lB"
      },
      "source": [
        "# train, test set 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "x = ratings.copy()\n",
        "y = ratings['user_id'] # user_id별로 train_set, test_set 비율 동일하게 유지.\n",
        "# len(ratings['user_id'].unique()): 943개 train, test set 분리\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fIk-IhTL-oA"
      },
      "source": [
        "# 모델별 RMSE를 계산하는 함수 \n",
        "def score(model):\n",
        "    id_pairs = zip(x_test['user_id'], x_test['movie_id']) # user, movie id pair 시킴.\n",
        "    y_pred = np.array([model(user, movie) for (user, movie) in id_pairs])\n",
        "    y_true = np.array(x_test['rating'])\n",
        "    return RMSE(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYc3br0pJpCZ"
      },
      "source": [
        "# train 데이터로 Full matrix 구하기 \n",
        "# 평가하지 않은 조합은 NaN.\n",
        "rating_matrix = x_train.pivot(index='user_id', columns='movie_id', values='rating')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiA8OHd8OUZG",
        "outputId": "b848c6a0-db70-411c-d2d8-9d22a2171e34"
      },
      "source": [
        "# 전체 평균으로 예측치를 계산하는 기본 모델\n",
        "# try,except는 test data에만 있는 영화로 인해 발생하는 오류 방지\n",
        "def best_seller(user_id, movie_id):\n",
        "    try:\n",
        "        rating = train_mean[movie_id]\n",
        "    except:\n",
        "        rating = 3.0\n",
        "    return rating\n",
        "\n",
        "train_mean = x_train.groupby(['movie_id'])['rating'].mean()\n",
        "score(best_seller)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0262391483556985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BddUE_yOUbx"
      },
      "source": [
        "# 성별 기준 집단 생성 후 예측값 계산. (공통키인 user_id 기준)\n",
        "\n",
        "merged_ratings = pd.merge(x_train, users)\n",
        "users = users.set_index('user_id')\n",
        "\n",
        "# gender별 평점평균 계산\n",
        "g_mean = merged_ratings[['movie_id', 'sex', 'rating']].groupby(['movie_id', 'sex'])['rating'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDGjT3eUOUei",
        "outputId": "81be10d5-3d27-4bfd-b266-ac5890519cff"
      },
      "source": [
        "# gender별 평균을 예측치로 돌려주는 함수 \n",
        "def cf_gender(user_id, movie_id):\n",
        "    if movie_id in rating_matrix:\n",
        "        gender = users.loc[user_id]['sex']\n",
        "        if gender in g_mean[movie_id]: # 성별이 치우쳐져 rating 되어있을 수 있음.\n",
        "            gender_rating = g_mean[movie_id][gender]\n",
        "        else:\n",
        "            gender_rating = 3.0\n",
        "    else:\n",
        "        gender_rating = 3.0\n",
        "    return gender_rating\n",
        "\n",
        "score(cf_gender) # 성별에 따른 추천이 정확도 개선하지 못한다.(오히려 떨어짐)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0368477869381156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJIyF1eUHsGX"
      },
      "source": [
        "### 제 3장 협업 필터링 추천 시스템\n",
        "\n",
        ": 인구통계적 변수를 기준으로 나누지 않고, 취향을 기준으로 나눌 것.\n",
        "\n",
        ": 취향이 비슷한 사람들의 집단(neighbor)이 존재한다고 가정. 각 사용자의 평가의 유사성(simliarity) 계산."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJFCWmfOomm2"
      },
      "source": [
        "#### 유사도 지표\n",
        "\n",
        "(1) 상관계수\n",
        "\n",
        "(2) 코사인 유사도: 아이템(차원), 사용자의 평가값(좌표값)\n",
        "\n",
        "-> 두 사용자의 평가값이 유사할수록 각도가 작다.\n",
        "\n",
        "(3) 타니모토 계수: binary data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r1JBhdNWVHU"
      },
      "source": [
        "# train set의 모든 가능한 사용자 pair의 Cosine similarities 계산\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "matrix_dummy = rating_matrix.copy().fillna(0) # NA->0\n",
        "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy) # 대칭 matrix\n",
        "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
        "# index 지정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9gppVQcAChG",
        "outputId": "d1cb6f02-6e41-4bfe-a5bc-6a61d4ae50a8"
      },
      "source": [
        "# 주어진 영화의 (movie_id) 가중평균 rating을 계산하는 함수, \n",
        "# 가중치는 주어진 사용자와 다른 사용자 간의 유사도(user_similarity)\n",
        "def CF_simple(user_id, movie_id):\n",
        "    if movie_id in rating_matrix:\n",
        "        sim_scores = user_similarity[user_id].copy()\n",
        "        movie_ratings = rating_matrix[movie_id].copy()\n",
        "        # 현재 영화를 평가하지 않은 사용자의 index 가져오기 (가중평균 계산에서 빼기 위해)\n",
        "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
        "        # 현재 영화를 평가하지 않은 사용자의 rating (null) 제거\n",
        "        movie_ratings = movie_ratings.dropna()\n",
        "        # 현재 영화를 평가하지 않은 사용자의 similarity값 제거\n",
        "        sim_scores = sim_scores.drop(none_rating_idx)\n",
        "        # 현재 영화를 평가한 모든 사용자의 가중평균값 구하기\n",
        "        mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "    else:\n",
        "        mean_rating = 3.0\n",
        "    return mean_rating\n",
        "\n",
        "# 정확도 계산 (성별, 직업별 평균보다 개선됨)\n",
        "score(CF_simple)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0208231645078234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9YYInM6ZNRG"
      },
      "source": [
        "#### 이웃을 고려한 CF\n",
        "\n",
        "-> 이웃의 크기 줄이기\n",
        "\n",
        "-> K-nearest negihbors/Thresholding (이웃의 기준 변경)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch7gfBCJWVMl"
      },
      "source": [
        "# 모델별 RMSE를 계산하는 함수 \n",
        "def score(model, neighbor_size=0):\n",
        "    id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
        "    y_pred = np.array([model(user, movie, neighbor_size) for (user, movie) in id_pairs])\n",
        "    y_true = np.array(x_test['rating'])\n",
        "    return RMSE(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St4n9-bUZyEq",
        "outputId": "c717c5f8-e7cc-4415-8431-e5eed1fe71ef"
      },
      "source": [
        "# Neighbor size를 정해서 예측치를 계산하는 함수 \n",
        "def cf_knn(user_id, movie_id, neighbor_size=0):\n",
        "    if movie_id in rating_matrix:\n",
        "        sim_scores = user_similarity[user_id].copy()\n",
        "        movie_ratings = rating_matrix[movie_id].copy()\n",
        "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
        "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
        "        sim_scores = sim_scores.drop(none_rating_idx)\n",
        "\n",
        "##### (2) Neighbor size가 지정되지 않은 경우        \n",
        "        if neighbor_size == 0:          \n",
        "            # 현재 영화를 평가한 모든 사용자의 가중평균값 구하기\n",
        "            mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "\n",
        "##### (3) Neighbor size가 지정된 경우\n",
        "        else:                       \n",
        "            # 해당 영화를 평가한 사용자가 최소 2명이 되는 경우에만 계산\n",
        "            if len(sim_scores) > 1: \n",
        "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
        "                sim_scores = np.array(sim_scores)\n",
        "                movie_ratings = np.array(movie_ratings)\n",
        "                # 유사도를 순서대로 정렬\n",
        "                user_idx = np.argsort(sim_scores)\n",
        "                # 가장 유사도가 높은 k명의 사용자 선정.\n",
        "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
        "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
        "                mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "            else:\n",
        "                mean_rating = 3.0\n",
        "    else:\n",
        "        mean_rating = 3.0\n",
        "    return mean_rating\n",
        "\n",
        "# 정확도 계산 (이웃의 크기 고려하니 약간 개선됨.)\n",
        "score(cf_knn, neighbor_size=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0119463875917478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcwdMsCev1I"
      },
      "source": [
        "#### 주어진 사용자에 대한 추천받기."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2LUCHZcZyIa"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# 실제 추천을 할 때에는 train, test set 나눌 필요 없음.\n",
        "rating_matrix = ratings.pivot_table(values='rating', index='user_id', columns='movie_id')\n",
        "matrix_dummy = rating_matrix.copy().fillna(0)\n",
        "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
        "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xH2LyuGfHsB"
      },
      "source": [
        "def recom_movie(user_id, n_items, neighbor_size=30):\n",
        "    # 현 사용자가 평가한 평점 데이터만 가져오기\n",
        "    user_movie = rating_matrix.loc[user_id].copy()\n",
        "    for movie in rating_matrix:\n",
        "        # 현 사용자가 이미 평가한 영화는 제외 (평점을 0으로)        \n",
        "        if pd.notnull(user_movie.loc[movie]):\n",
        "            user_movie.loc[movie] = 0\n",
        "        else:\n",
        "            user_movie.loc[movie] = cf_knn(user_id, movie, neighbor_size)\n",
        "\n",
        "    # 영화를 예상 평점에 따라 정렬해서 제목을 뽑아서 돌려 줌\n",
        "    movie_sort = user_movie.sort_values(ascending=False)[:n_items]\n",
        "    recom_movies = movies.loc[movie_sort.index] # 영화 정보 추출\n",
        "    recommendations = recom_movies['title']\n",
        "    return recommendations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chFSuzF4fHuU",
        "outputId": "30433adf-46fa-425e-9a15-ac1b2e0a344d"
      },
      "source": [
        "recom_movie(user_id=2, n_items=5, neighbor_size=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "movie_id\n",
              "1293                     Ayn Rand: A Sense of Life (1997)\n",
              "1189                              That Old Feeling (1997)\n",
              "1467                                     Cure, The (1995)\n",
              "1500    Prisoner of the Mountains (Kavkazsky Plennik) ...\n",
              "318                       Everyone Says I Love You (1996)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2rLnKPveXm5"
      },
      "source": [
        "#### 최적의 neighbor size 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWTO7XTACjL",
        "outputId": "49b107aa-0c41-41ab-e154-4378e73655d7"
      },
      "source": [
        "# train set으로 full matrix와 cosine similarity 구하기 \n",
        "rating_matrix = x_train.pivot_table(values='rating', index='user_id', columns='movie_id')\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "matrix_dummy = rating_matrix.copy().fillna(0)\n",
        "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
        "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
        "for neighbor_size in [10, 20, 30, 40, 50, 60]:\n",
        "    print(\"Neighbor size = %d : RMSE = %.4f\" % (neighbor_size, score(cf_knn, neighbor_size)))\n",
        "\n",
        " # neighbor size가 30 정도에서 최소가 된다.\n",
        " # 그 후, 더 세밀하게 1단위로 변화시키면서 결과를 보면 된다.   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neighbor size = 10 : RMSE = 1.0300\n",
            "Neighbor size = 20 : RMSE = 1.0144\n",
            "Neighbor size = 30 : RMSE = 1.0119\n",
            "Neighbor size = 40 : RMSE = 1.0121\n",
            "Neighbor size = 50 : RMSE = 1.0130\n",
            "Neighbor size = 60 : RMSE = 1.0136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMb6kv1NhPlB"
      },
      "source": [
        "#### 사용자의 평가경향(user bias)을 고려한 CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry6XSBXXlEjL"
      },
      "source": [
        "# train 데이터의 user의 rating 평균과 영화의 평점편차 계산 \n",
        "rating_mean = rating_matrix.mean(axis=1)\n",
        "rating_bias = (rating_matrix.T - rating_mean).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNHnRTpRAEHw"
      },
      "source": [
        "def CF_knn_bias(user_id, movie_id, neighbor_size=0):\n",
        "    if movie_id in rating_bias:\n",
        "        sim_scores = user_similarity[user_id].copy()\n",
        "        # 현 movie의 평점편차 가져오기\n",
        "        movie_ratings = rating_bias[movie_id].copy()\n",
        "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
        "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
        "        sim_scores = sim_scores.drop(none_rating_idx)\n",
        "##### (2) Neighbor size가 지정되지 않은 경우        \n",
        "        if neighbor_size == 0:\n",
        "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "            prediction = prediction + rating_mean[user_id]\n",
        "##### (3) Neighbor size가 지정된 경우            \n",
        "        else:           \n",
        "            if len(sim_scores) > 1:\n",
        "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
        "                sim_scores = np.array(sim_scores)\n",
        "                movie_ratings = np.array(movie_ratings)\n",
        "                user_idx = np.argsort(sim_scores)\n",
        "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
        "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
        "                # 편차로 예측치 계산(예측치를 평점편차로 구함)\n",
        "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "                # 예측값에 현 사용자의 평균 더하기\n",
        "                prediction = prediction + rating_mean[user_id]\n",
        "            else:\n",
        "                prediction = rating_mean[user_id]\n",
        "    else:\n",
        "        prediction = rating_mean[user_id]\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnk63fWKh9Yn",
        "outputId": "b3cde22a-6d6a-4def-f5ae-49ef15cfc2df"
      },
      "source": [
        "score(CF_knn_bias, 30) # 평가 경향 고려했더니 개선됨."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9441961190466248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnXoAItQmQS_"
      },
      "source": [
        "#### 신뢰도 가중\n",
        "\n",
        ": 공통으로 평가한 아이템의 수가 일정값 이상인 사용자만 이웃 사용자로 활용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7jkQA2emdBX"
      },
      "source": [
        "# 공통으로 평가한 아이템의 수 계산\n",
        "\n",
        "rating_binary1 = np.array((rating_matrix > 0).astype(float)) # 평점이 있는 경우만 1\n",
        "rating_binary2 = rating_binary1.T\n",
        "counts = np.dot(rating_binary1, rating_binary2)\n",
        "# 행렬의 각 원소는 각각의 사용자가 공통으로 평가한 영화의 수\n",
        "# digonal은 각 사용자가 평가한 영화의 수\n",
        "counts = pd.DataFrame(counts, index=rating_matrix.index, columns=rating_matrix.index).fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU4vzdzyh9ay"
      },
      "source": [
        "def CF_knn_bias_sig(user_id, movie_id, neighbor_size=0):\n",
        "    if movie_id in rating_bias:\n",
        "        sim_scores = user_similarity[user_id]\n",
        "        movie_ratings = rating_bias[movie_id]\n",
        "        # 현 movie에 대한 rating이 없는 사용자 표시\n",
        "        no_rating = movie_ratings.isnull()\n",
        "        # 현 사용자와 다른 사용자간 공통 평가 아이템 수 가져오기 \n",
        "        common_counts = counts[user_id]\n",
        "        # 공통으로 평가한 영화의 수가 SIG_LEVEL보다 낮은 사용자 표시\n",
        "        low_significance = common_counts < SIG_LEVEL\n",
        "        # 평가를 안 하였거나, SIG_LEVEL이 기준 이하인 user 제거\n",
        "        none_rating_idx = movie_ratings[no_rating | low_significance].index\n",
        "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
        "        sim_scores = sim_scores.drop(none_rating_idx)\n",
        "##### (2) Neighbor size가 지정되지 않은 경우        \n",
        "        if neighbor_size == 0:\n",
        "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "            prediction = prediction + rating_mean[user_id]\n",
        "##### (3) Neighbor size가 지정된 경우            \n",
        "        else:\n",
        "            # 해당 영화를 평가한 사용자가 최소 MIN_RATINGS 이상인 경우에만 계산            \n",
        "            if len(sim_scores) > MIN_RATINGS:\n",
        "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
        "                sim_scores = np.array(sim_scores)\n",
        "                movie_ratings = np.array(movie_ratings)\n",
        "                user_idx = np.argsort(sim_scores)\n",
        "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
        "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
        "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "                prediction = prediction + rating_mean[user_id]\n",
        "            else:\n",
        "                prediction = rating_mean[user_id]\n",
        "    else:\n",
        "        prediction = rating_mean[user_id]\n",
        "    return prediction\n",
        "\n",
        "SIG_LEVEL = 3 #최소 신뢰도(공통 평가 영화 수)\n",
        "MIN_RATINGS = 2 #최소 사용자 수(현재 영화를 평가한 사용자 수)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TD4Ed7ih90F",
        "outputId": "69da4fe9-6a34-4898-aa30-19ea3e9a1190"
      },
      "source": [
        "score(CF_knn_bias_sig, 30) #이웃의 수 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.943348411794892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJo4wEatoV-f"
      },
      "source": [
        "#### Item-Based CF\n",
        "\n",
        ": 예측 대상 사용자가 평가한 아이템의 평점과 다른 각 아이템과의 유사도를 가중해서 평균한 값을 그 아이템에 대한 예측값으로 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgGy8Hobo3hk"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "rating_matrix_t = np.transpose(rating_matrix)\n",
        "matrix_dummy = rating_matrix_t.copy().fillna(0)\n",
        "item_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
        "item_similarity = pd.DataFrame(item_similarity, index=rating_matrix_t.index, columns=rating_matrix_t.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21vt6Mmph92D"
      },
      "source": [
        "# 주어진 영화의 (movie_id) 가중평균 rating을 계산하는 함수, \n",
        "# 가중치는 주어진 아이템과 다른 아이템 간의 유사도(item_similarity)\n",
        "\n",
        "def CF_IBCF(user_id, movie_id):\n",
        "    if movie_id in item_similarity:      # 현재 영화가 train set에 있는지 확인\n",
        "        # 현재 영화와 다른 영화의 similarity 값 가져오기\n",
        "        sim_scores = item_similarity[movie_id]\n",
        "        # 현 사용자의 모든 rating 값 가져오기\n",
        "        user_rating = rating_matrix_t[user_id]\n",
        "        # 사용자가 평가하지 않은 영화 index 가져오기\n",
        "        non_rating_idx = user_rating[user_rating.isnull()].index\n",
        "        # 사용자가 평가하지 않은 영화 제거\n",
        "        user_rating = user_rating.dropna()\n",
        "        # 사용자가 평가하지 않은 영화의 similarity 값 제거\n",
        "        sim_scores = sim_scores.drop(non_rating_idx)\n",
        "        # 현 영화에 대한 예상 rating 계산, 가중치는 현 영화와 사용자가 평가한 영화의 유사도\n",
        "        mean_rating = np.dot(sim_scores, user_rating) / sim_scores.sum()\n",
        "    else:\n",
        "        mean_rating = 3.0\n",
        "    return mean_rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8bOdn5Gpgsq"
      },
      "source": [
        "def score(model):\n",
        "    id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
        "    y_pred = np.array([model(user, movie) for (user, movie) in id_pairs])\n",
        "    y_true = np.array(x_test['rating'])\n",
        "    return RMSE(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWiwYh6qh94m",
        "outputId": "e184b106-3da2-4aca-cf43-799e1e4db047"
      },
      "source": [
        "score(CF_IBCF) #UBCF와 큰 차이는 없음."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0177868674759176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTgoZpcOqdi2"
      },
      "source": [
        "#### 추천 시스템의 성과측정지표\n",
        "\n",
        ": binary data일 경우, 추천 아이템과 사용자가 실제 선택한 아이템을 비교하여야 한다.\n",
        "\n",
        "=> precision(정밀도): 추천 시스템이 추천한 아이템 중 실제 사용자가 선택한 아이템의 비율\n",
        "\n",
        "=> recall(재현율): 사용자가 실제로 선택한 전체 아이템 중에서 몇 개의 아이템을 올바르게 맞췄는가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWhLhYimpsig"
      },
      "source": [
        "### 제 4장 Matrix Factorization 기반 추천\n",
        "\n",
        "모델 기반 알고리즘: 데이터로부터 추천을 위한 모델을 구성한 후에 이 모델만 저장하고, 실제 추천을 할 때에는 이 모델을 사용해서 추천을 하는 방식. 약한 신호도 더 잘 잡아낸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jivz5Efsljg"
      },
      "source": [
        "#### MF 방식의 원리\n",
        "\n",
        "MF(행렬 요인화): 평가 데이터 (사용자X아이템으로 구성된) 하나의 행렬을 2개의 행렬(사용자 행렬(P), 아이템 행렬(Q))로 분해하는 방법\n",
        "\n",
        "P,Q 행렬에서 공통인 K개의 요인(잠재요인)\n",
        "\n",
        "=> 잠재요인을 보면 어떤 영화가 어떤 사용자 취향에 맞을지 예상할 수 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTgHWIAIuWhA"
      },
      "source": [
        "#### SGD(stochastic gradient decent)를 사용한 MF 알고리즘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6HloBy0h96c"
      },
      "source": [
        "# MF class\n",
        "class MF():\n",
        "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
        "        self.R = np.array(ratings)\n",
        "        self.num_users, self.num_items = np.shape(self.R)\n",
        "        self.K = K # 잠재요인의 수\n",
        "        self.alpha = alpha # 학습률\n",
        "        self.beta = beta # 정규화 계수\n",
        "        self.iterations = iterations # sgd 계산을 할 때의 반복 횟수\n",
        "        self.verbose = verbose # sgd 중간 학습과정 출력 여부\n",
        "\n",
        "    # Root Mean Squared Error (RMSE) 계산\n",
        "    def rmse(self):\n",
        "        xs, ys = self.R.nonzero() # R에서 평점이 있는 요소의 인덱스 가져옴.\n",
        "        self.predictions = []\n",
        "        self.errors = []\n",
        "        for x, y in zip(xs, ys):\n",
        "            prediction = self.get_prediction(x, y)\n",
        "            self.predictions.append(prediction)\n",
        "            self.errors.append(self.R[x, y] - prediction)\n",
        "        self.predictions = np.array(self.predictions)\n",
        "        self.errors = np.array(self.errors)\n",
        "        return np.sqrt(np.mean(self.errors**2)) # error 사용하여 RMSE 계산\n",
        "\n",
        "    def train(self): # 정해진 횟수 만큼 P,Q,bu,bd값 업데이트\n",
        "\n",
        "        # 평균 0, 표준편차:1/k인 정규분포 난수로 초기화\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
        "\n",
        "        # bu,bd 초기화 + 전체평균 b 저장\n",
        "        self.b_u = np.zeros(self.num_users)\n",
        "        self.b_d = np.zeros(self.num_items)\n",
        "        self.b = np.mean(self.R[self.R.nonzero()])\n",
        "\n",
        "        # R 중 평점이 있는 요소의 인덱스 가져옴.\n",
        "        rows, columns = self.R.nonzero()\n",
        "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
        "\n",
        "        # SGD 개선 기록, 10회 반복마다 중간 결과 표시\n",
        "        training_process = []\n",
        "        for i in range(self.iterations):\n",
        "            np.random.shuffle(self.samples)\n",
        "            self.sgd()\n",
        "            rmse = self.rmse()\n",
        "            training_process.append((i+1, rmse))\n",
        "            if self.verbose:\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(\"Iteration: %d ; Train RMSE = %.4f \" % (i+1, rmse))\n",
        "        return training_process\n",
        "\n",
        "    # 평점 예측값 구하는 함수.\n",
        "    def get_prediction(self, i, j):\n",
        "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
        "        return prediction\n",
        "\n",
        "    # SGD 실행 함수\n",
        "    def sgd(self):\n",
        "        for i, j, r in self.samples:\n",
        "            prediction = self.get_prediction(i, j)\n",
        "            e = (r - prediction)\n",
        "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
        "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
        "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
        "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkrWE-tHsiY7",
        "outputId": "01424680-62d6-4bd8-dcec-619fb8bc43d6"
      },
      "source": [
        "# 전체 데이터 사용 MF\n",
        "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
        "mf = MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
        "train_process = mf.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; Train RMSE = 0.9585 \n",
            "Iteration: 20 ; Train RMSE = 0.9373 \n",
            "Iteration: 30 ; Train RMSE = 0.9280 \n",
            "Iteration: 40 ; Train RMSE = 0.9225 \n",
            "Iteration: 50 ; Train RMSE = 0.9184 \n",
            "Iteration: 60 ; Train RMSE = 0.9145 \n",
            "Iteration: 70 ; Train RMSE = 0.9099 \n",
            "Iteration: 80 ; Train RMSE = 0.9036 \n",
            "Iteration: 90 ; Train RMSE = 0.8947 \n",
            "Iteration: 100 ; Train RMSE = 0.8826 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jd2ZT-Qzyf2"
      },
      "source": [
        "#### train,test 분리 MF 알고리즘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEDLZuPW0bFD"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "TRAIN_SIZE = 0.75\n",
        "ratings = shuffle(ratings, random_state=1)\n",
        "cutoff = int(TRAIN_SIZE * len(ratings)) # 전체 데이터 중 Train set의 데이터 개수\n",
        "ratings_train = ratings.iloc[:cutoff]\n",
        "ratings_test = ratings.iloc[cutoff:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVtcJvzDh984"
      },
      "source": [
        "# New MF class for training & testing\n",
        "# 사용자 아이디(user_id)와 아이템 아이디(item_id)를 인덱스와 맵핑한다.\n",
        "\n",
        "class NEW_MF():\n",
        "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
        "        self.R = np.array(ratings)\n",
        "##### >>>>> (2) user_id, item_id를 R의 index와 매핑하기 위한 dictionary 생성\n",
        "        item_id_index = []\n",
        "        index_item_id = []\n",
        "        for i, one_id in enumerate(ratings):\n",
        "            item_id_index.append([one_id, i])\n",
        "            index_item_id.append([i, one_id])\n",
        "        self.item_id_index = dict(item_id_index)\n",
        "        self.index_item_id = dict(index_item_id)\n",
        "\n",
        "        user_id_index = []\n",
        "        index_user_id = []\n",
        "        for i, one_id in enumerate(ratings.T):\n",
        "            user_id_index.append([one_id, i])\n",
        "            index_user_id.append([i, one_id])\n",
        "        self.user_id_index = dict(user_id_index)\n",
        "        self.index_user_id = dict(index_user_id)\n",
        "\n",
        "#### <<<<< (2)\n",
        "        self.num_users, self.num_items = np.shape(self.R)\n",
        "        self.K = K\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.iterations = iterations\n",
        "        self.verbose = verbose\n",
        "    # train set의 RMSE 계산\n",
        "    def rmse(self):\n",
        "        xs, ys = self.R.nonzero()\n",
        "        self.predictions = []\n",
        "        self.errors = []\n",
        "        for x, y in zip(xs, ys):\n",
        "            prediction = self.get_prediction(x, y)\n",
        "            self.predictions.append(prediction)\n",
        "            self.errors.append(self.R[x, y] - prediction)\n",
        "        self.predictions = np.array(self.predictions)\n",
        "        self.errors = np.array(self.errors)\n",
        "        return np.sqrt(np.mean(self.errors**2))\n",
        "    # Ratings for user i and item j\n",
        "    def get_prediction(self, i, j):\n",
        "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
        "        return prediction\n",
        "    # Stochastic gradient descent to get optimized P and Q matrix\n",
        "    def sgd(self):\n",
        "        for i, j, r in self.samples:\n",
        "            prediction = self.get_prediction(i, j)\n",
        "            e = (r - prediction)\n",
        "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
        "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
        "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
        "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
        "\n",
        "##### >>>>> (3)\n",
        "    # Test set을 선정\n",
        "    def set_test(self, ratings_test):\n",
        "        test_set = []\n",
        "        for i in range(len(ratings_test)):      # test 데이터에 있는 각 데이터에 대해서\n",
        "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
        "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
        "            z = ratings_test.iloc[i, 2] # 현재 사용자-아이템의 평점\n",
        "            test_set.append([x, y, z])\n",
        "            self.R[x, y] = 0                    # Setting test set ratings to 0\n",
        "        self.test_set = test_set\n",
        "        return test_set                       \n",
        "\n",
        "    # Test set의 RMSE 계산\n",
        "    def test_rmse(self):\n",
        "        error = 0\n",
        "        for one_set in self.test_set:\n",
        "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
        "            error += pow(one_set[2] - predicted, 2)\n",
        "        return np.sqrt(error/len(self.test_set))\n",
        "\n",
        "    # Training 하면서 test set의 정확도를 계산\n",
        "    def test(self):\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
        "        self.b_u = np.zeros(self.num_users)\n",
        "        self.b_d = np.zeros(self.num_items)\n",
        "        self.b = np.mean(self.R[self.R.nonzero()])\n",
        "\n",
        "        # List of training samples\n",
        "        rows, columns = self.R.nonzero() #train set에서 test set에 해당하는 부분은 0으로 바꾸었기 때문에, R 전체가 train set이 된다.\n",
        "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
        "\n",
        "        # SGD\n",
        "        training_process = []\n",
        "        for i in range(self.iterations):\n",
        "            np.random.shuffle(self.samples)\n",
        "            self.sgd()\n",
        "            rmse1 = self.rmse() # train set의 RMSE\n",
        "            rmse2 = self.test_rmse() # test set의 RMSE\n",
        "            training_process.append((i+1, rmse1, rmse2))\n",
        "            if self.verbose:\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
        "        return training_process\n",
        "\n",
        "    # Ratings for given user_id and item_id\n",
        "    def get_one_prediction(self, user_id, item_id):\n",
        "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
        "\n",
        "    # Full user-movie rating matrix\n",
        "    def full_prediction(self):\n",
        "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_94-h_ZXh9_C",
        "outputId": "3f4a7d28-3b97-4875-d1b1-1e1dd5232fad"
      },
      "source": [
        "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
        "mf = NEW_MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
        "test_set = mf.set_test(ratings_test)\n",
        "result = mf.test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; Train RMSE = 0.9659 ; Test RMSE = 0.9834\n",
            "Iteration: 20 ; Train RMSE = 0.9410 ; Test RMSE = 0.9645\n",
            "Iteration: 30 ; Train RMSE = 0.9298 ; Test RMSE = 0.9567\n",
            "Iteration: 40 ; Train RMSE = 0.9231 ; Test RMSE = 0.9524\n",
            "Iteration: 50 ; Train RMSE = 0.9184 ; Test RMSE = 0.9497\n",
            "Iteration: 60 ; Train RMSE = 0.9145 ; Test RMSE = 0.9479\n",
            "Iteration: 70 ; Train RMSE = 0.9109 ; Test RMSE = 0.9464\n",
            "Iteration: 80 ; Train RMSE = 0.9069 ; Test RMSE = 0.9451\n",
            "Iteration: 90 ; Train RMSE = 0.9020 ; Test RMSE = 0.9436\n",
            "Iteration: 100 ; Train RMSE = 0.8957 ; Test RMSE = 0.9418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1xbllYW0P1f",
        "outputId": "91b31e7d-3597-48f2-e566-695fa8b2b9ab"
      },
      "source": [
        "print(mf.full_prediction())\n",
        "print(mf.get_one_prediction(1, 2)) # user_id가 1인 사용자의 item_id 2번 아이템에 대한 예측치"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.83831727 3.42728376 3.06180202 ... 3.34209285 3.47416976 3.46382333]\n",
            " [3.91471585 3.49663837 3.14996475 ... 3.43267438 3.54809987 3.54228495]\n",
            " [3.28950795 2.89736005 2.53706809 ... 2.81544201 2.93304898 2.93332613]\n",
            " ...\n",
            " [4.20962379 3.79153408 3.43862173 ... 3.72131153 3.83076693 3.81890373]\n",
            " [4.3242727  3.89567571 3.56321549 ... 3.82291673 3.93934757 3.93963273]\n",
            " [3.73904627 3.3600233  2.99424802 ... 3.3024826  3.44593186 3.41606257]]\n",
            "3.427283757709133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXKUhJ860CAc"
      },
      "source": [
        "#### MF의 최적 파라미터 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "002uFj9yh-CZ",
        "outputId": "e9ce1fe9-e898-4f93-c8c3-5a638ce58f7c"
      },
      "source": [
        "# 최적의 K값 찾기\n",
        "results = []\n",
        "index = []\n",
        "for K in range(200, 211, 10): # 시간 많이 걸려서 200,210만 했어요\n",
        "    print('K =', K)\n",
        "    R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
        "    mf = NEW_MF(R_temp, K=K, alpha=0.001, beta=0.02, iterations=30, verbose=True)\n",
        "    test_set = mf.set_test(ratings_test) # 앞에서 분리한 test set 지정.\n",
        "    result = mf.test()\n",
        "    index.append(K)\n",
        "    results.append(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K = 200\n",
            "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
            "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
            "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
            "K = 210\n",
            "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
            "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9645\n",
            "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZgnHVSf2h-D8",
        "outputId": "0602d116-fbcc-4cfe-cd50-99d2f96d3596"
      },
      "source": [
        "# 최적의 iterations 값 찾기\n",
        "summary = []\n",
        "for i in range(len(results)):\n",
        "    RMSE = []\n",
        "    for result in results[i]:\n",
        "        RMSE.append(result[2])\n",
        "    min = np.min(RMSE)\n",
        "    j = RMSE.index(min)\n",
        "    summary.append([index[i], j+1, RMSE[j]])\n",
        "\n",
        "# 그래프 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(index, [x[2] for x in summary])\n",
        "plt.ylim(0.99, 0.94)\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('RMSE')\n",
        "plt.show() # K=200을 최적의 K로 볼 것."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U_1HX9T6qOy"
      },
      "source": [
        "### 제 5장 Surprise 패키지 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DOfTwXDgcLL",
        "outputId": "61f4ec8a-dbad-4cfb-ab8f-c17e3bcf9e72"
      },
      "source": [
        "! pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1617541 sha256=ad9dd6dc9d48caeaadba53f68d790cc968abe227453c353d2c670d255fd813f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S-uO4GcgcNc"
      },
      "source": [
        "from surprise import BaselineOnly\n",
        "from surprise import KNNWithMeans\n",
        "from surprise import SVD\n",
        "from surprise import SVDpp\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YPXlkR0gcQA",
        "outputId": "efdd925d-0dfe-4820-f8b3-0ff81f6a1793"
      },
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "algo = KNNWithMeans()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9540080061420287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "_lOcYNTKgcSf",
        "outputId": "db170f53-5b90-44cc-f386-013926812aae"
      },
      "source": [
        "# 알고리즘 비교\n",
        "algorithms = [BaselineOnly, KNNWithMeans, SVD, SVDpp] # 여기서는 SVDpp가 가장 정확.\n",
        "names = []\n",
        "results = []\n",
        "for option in algorithms:\n",
        "    algo = option()\n",
        "    names.append(option.__name__)       # 알고리즘 이름 \n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    results.append(accuracy.rmse(predictions))\n",
        "names = np.array(names)\n",
        "results = np.array(results)\n",
        "\n",
        "# 결과를 그래프로 표시\n",
        "import matplotlib.pyplot as plt\n",
        "index = np.argsort(results) #정확도 순서대로 정렬한 인덱스 받아온다\n",
        "plt.ylim(0.8, 1)\n",
        "plt.plot(names[index], results[index])\n",
        "results[index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "RMSE: 0.9467\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9540\n",
            "RMSE: 0.9417\n",
            "RMSE: 0.9230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92300196, 0.94174704, 0.94669289, 0.95400801])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tqRCTvmgcUE",
        "outputId": "278fbd50-0bcf-4c73-abda-73990b5e82bb"
      },
      "source": [
        "# 알고리즘 옵션 변경, 정확도 계산\n",
        "sim_options = {'name': 'pearson_baseline',\n",
        "               'user_based': True}\n",
        "algo = KNNWithMeans(k=30, sim_options=sim_options)\n",
        "\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.942176868902798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsmLs7TB_JxX",
        "outputId": "b79f2eb9-c382-41e2-ac3c-78f16ce834a1"
      },
      "source": [
        "# 다양한 Neighbor size 비교, 여기서는 K=40일때 최선.\n",
        "result = []\n",
        "for neighbor_size in (10, 20, 30, 40, 50, 60):\n",
        "    algo = KNNWithMeans(k=neighbor_size, sim_options={'name':\n",
        "           'pearson_baseline', 'user_based': True}) # UBCF사용, 유사도지표:pearson_baseline\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    result.append([neighbor_size, accuracy.rmse(predictions)])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9565\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9442\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9422\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9415\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9418\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 0.9565477041648505],\n",
              " [20, 0.9441555760179853],\n",
              " [30, 0.942176868902798],\n",
              " [40, 0.9415067906687419],\n",
              " [50, 0.9417847292665135],\n",
              " [60, 0.9422154447789063]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVTCKv2z_J0d",
        "outputId": "0273d983-83b4-4b9b-c537-17722c49a02f"
      },
      "source": [
        "# KNN 다양한 파라메터 비교\n",
        "from surprise.model_selection import GridSearchCV\n",
        "param_grid = {'k': [5, 10, 15, 25],\n",
        "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\n",
        "                              'user_based': [True, False]} # UBCF,IBCF 비교\n",
        "              }\n",
        "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=4)\n",
        "gs.fit(data)\n",
        "\n",
        "# 최적 RMSE 출력\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# 최적 RMSE의 parameter\n",
        "print(gs.best_params['rmse'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "0.9251290211932715\n",
            "{'k': 25, 'sim_options': {'name': 'pearson_baseline', 'user_based': False}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "oxn9cAxg_J2i",
        "outputId": "5551e411-c242-4a85-9bcc-63057ccda1a9"
      },
      "source": [
        "# SVD 다양한 파라메터 비교\n",
        "from surprise.model_selection import GridSearchCV\n",
        "param_grid = {'n_epochs': [70, 80, 90],\n",
        "              'lr_all': [0.005, 0.006, 0.007],\n",
        "              'reg_all': [0.05, 0.07, 0.1]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5,n_)\n",
        "gs.fit(data) # 너무 오래걸려여,,,\n",
        "\n",
        "# 최적 RMSE 출력\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# 최적 RMSE의 parameter\n",
        "print(gs.best_params['rmse'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-a40871eb4975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               'reg_all': [0.05, 0.07, 0.1]}\n\u001b[1;32m      6\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 최적 RMSE 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/model_selection/search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     88\u001b[0m         out = Parallel(n_jobs=self.n_jobs,\n\u001b[1;32m     89\u001b[0m                        \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                        verbose=self.joblib_verbose)(delayed_list)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         (test_measures_dicts,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/model_selection/validation.py\u001b[0m in \u001b[0;36mfit_and_score\u001b[0;34m(algo, trainset, testset, measures, return_train_measures)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mstart_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mstart_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/surprise/trainset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIw1aE_H1wHx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "dbf58753-56fd-4346-8f18-6a7075eb2a39"
      },
      "source": [
        "from surprise.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-16fd807309be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNNlatgi_J6M",
        "outputId": "37927ef5-dcd4-48e6-b575-456578b47e69"
      },
      "source": [
        "# 외부 데이터 불러오기\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
        "reader = Reader(rating_scale=(1,5))\n",
        "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', # Surprise의 Dataset 클래스로 읽어오면 된다.\n",
        "        'rating']], reader)\n",
        "\n",
        "# Train/Test 분리 \n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# 정확도 계산 \n",
        "algo = KNNWithMeans()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.954081617487824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGNQs0QIEqJJ"
      },
      "source": [
        "### 제 6장 딥러닝을 사용한 추천 시스템\n",
        "\n",
        "딥러닝: 다수의 은닉층을 가진 인공신경망을 적용하는 기법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s2iSiTENUrF"
      },
      "source": [
        "#### Keras로 MF 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG0-ksouLr0x"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD, Adamax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KfoNFrGLr4X"
      },
      "source": [
        "# Variable 초기화 \n",
        "K = 200                             # Latent factor 수 \n",
        "mu = ratings_train.rating.mean()    # 전체 평균 \n",
        "M = ratings.user_id.max() + 1       # Number of users\n",
        "N = ratings.movie_id.max() + 1      # Number of movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuID9xh_L7VJ"
      },
      "source": [
        "# Defining RMSE measure\n",
        "def RMSE(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9xqbX8MF4Z"
      },
      "source": [
        "# Keras model\n",
        "user = Input(shape=(1, ))                                               # User input\n",
        "item = Input(shape=(1, ))                                               # Item input\n",
        "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)        # (M, 1, K)\n",
        "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)        # (N, 1, K)\n",
        "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)          # User bias term (M, 1, )\n",
        "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)          # Item bias term (N, 1, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1qgLBJUMJUz"
      },
      "source": [
        "R = layers.dot([P_embedding, Q_embedding], axes=2)              \n",
        "R = layers.add([R, user_bias, item_bias])\n",
        "R = Flatten()(R) # 1차원의 배열로 변경."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I4LXMEMMJYo",
        "outputId": "4e667476-2b78-4b76-a6c8-21c5a5b21aa6"
      },
      "source": [
        "# Model setting\n",
        "model = Model(inputs=[user, item], outputs=R)\n",
        "model.compile(\n",
        "  loss=RMSE,\n",
        "  optimizer=SGD(),\n",
        "  #optimizer=Adamax(),\n",
        "  metrics=[RMSE]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 200)       188800      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 200)       336600      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
            "                                                                 embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 1)         944         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 1)         1683        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 1, 1)         0           dot[0][0]                        \n",
            "                                                                 embedding_2[0][0]                \n",
            "                                                                 embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1)            0           add[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 528,027\n",
            "Trainable params: 528,027\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy1ldWNO_J8N",
        "outputId": "3e71e938-a773-44ee-fbcd-a78f1a0f4d95"
      },
      "source": [
        "# Model fitting\n",
        "result = model.fit(\n",
        "  x=[ratings_train.user_id.values, ratings_train.movie_id.values],\n",
        "  y=ratings_train.rating.values - mu,\n",
        "  epochs=60,\n",
        "  batch_size=256,\n",
        "  validation_data=(\n",
        "    [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
        "    ratings_test.rating.values - mu\n",
        "  )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "293/293 [==============================] - 4s 9ms/step - loss: 5.3943 - RMSE: 1.1230 - val_loss: 5.0346 - val_RMSE: 1.1239\n",
            "Epoch 2/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 4.9210 - RMSE: 1.1221 - val_loss: 4.6003 - val_RMSE: 1.1221\n",
            "Epoch 3/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 4.4962 - RMSE: 1.1174 - val_loss: 4.2141 - val_RMSE: 1.1204\n",
            "Epoch 4/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 4.1247 - RMSE: 1.1193 - val_loss: 3.8706 - val_RMSE: 1.1188\n",
            "Epoch 5/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 3.7931 - RMSE: 1.1198 - val_loss: 3.5652 - val_RMSE: 1.1173\n",
            "Epoch 6/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 3.4935 - RMSE: 1.1154 - val_loss: 3.2936 - val_RMSE: 1.1159\n",
            "Epoch 7/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 3.2276 - RMSE: 1.1121 - val_loss: 3.0520 - val_RMSE: 1.1147\n",
            "Epoch 8/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 2.9955 - RMSE: 1.1135 - val_loss: 2.8372 - val_RMSE: 1.1135\n",
            "Epoch 9/60\n",
            "293/293 [==============================] - 2s 8ms/step - loss: 2.7860 - RMSE: 1.1115 - val_loss: 2.6461 - val_RMSE: 1.1124\n",
            "Epoch 10/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 2.6001 - RMSE: 1.1100 - val_loss: 2.4762 - val_RMSE: 1.1114\n",
            "Epoch 11/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 2.4374 - RMSE: 1.1114 - val_loss: 2.3252 - val_RMSE: 1.1105\n",
            "Epoch 12/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 2.2874 - RMSE: 1.1072 - val_loss: 2.1908 - val_RMSE: 1.1096\n",
            "Epoch 13/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 2.1573 - RMSE: 1.1068 - val_loss: 2.0713 - val_RMSE: 1.1088\n",
            "Epoch 14/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 2.0431 - RMSE: 1.1079 - val_loss: 1.9650 - val_RMSE: 1.1080\n",
            "Epoch 15/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.9367 - RMSE: 1.1041 - val_loss: 1.8705 - val_RMSE: 1.1073\n",
            "Epoch 16/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.8463 - RMSE: 1.1047 - val_loss: 1.7865 - val_RMSE: 1.1066\n",
            "Epoch 17/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.7680 - RMSE: 1.1074 - val_loss: 1.7117 - val_RMSE: 1.1060\n",
            "Epoch 18/60\n",
            "293/293 [==============================] - 2s 8ms/step - loss: 1.6926 - RMSE: 1.1040 - val_loss: 1.6453 - val_RMSE: 1.1055\n",
            "Epoch 19/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.6321 - RMSE: 1.1076 - val_loss: 1.5862 - val_RMSE: 1.1049\n",
            "Epoch 20/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.5659 - RMSE: 1.0982 - val_loss: 1.5336 - val_RMSE: 1.1044\n",
            "Epoch 21/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.5202 - RMSE: 1.1031 - val_loss: 1.4869 - val_RMSE: 1.1040\n",
            "Epoch 22/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.4700 - RMSE: 1.0979 - val_loss: 1.4453 - val_RMSE: 1.1035\n",
            "Epoch 23/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.4343 - RMSE: 1.1021 - val_loss: 1.4083 - val_RMSE: 1.1031\n",
            "Epoch 24/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.4011 - RMSE: 1.1044 - val_loss: 1.3754 - val_RMSE: 1.1028\n",
            "Epoch 25/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.3669 - RMSE: 1.1018 - val_loss: 1.3462 - val_RMSE: 1.1024\n",
            "Epoch 26/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.3377 - RMSE: 1.1007 - val_loss: 1.3202 - val_RMSE: 1.1021\n",
            "Epoch 27/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.3121 - RMSE: 1.1000 - val_loss: 1.2971 - val_RMSE: 1.1018\n",
            "Epoch 28/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.2935 - RMSE: 1.1035 - val_loss: 1.2765 - val_RMSE: 1.1015\n",
            "Epoch 29/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.2686 - RMSE: 1.0983 - val_loss: 1.2582 - val_RMSE: 1.1012\n",
            "Epoch 30/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.2529 - RMSE: 1.1001 - val_loss: 1.2419 - val_RMSE: 1.1010\n",
            "Epoch 31/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.2380 - RMSE: 1.1008 - val_loss: 1.2275 - val_RMSE: 1.1007\n",
            "Epoch 32/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.2254 - RMSE: 1.1021 - val_loss: 1.2146 - val_RMSE: 1.1005\n",
            "Epoch 33/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.2063 - RMSE: 1.0952 - val_loss: 1.2032 - val_RMSE: 1.1003\n",
            "Epoch 34/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1995 - RMSE: 1.0993 - val_loss: 1.1930 - val_RMSE: 1.1001\n",
            "Epoch 35/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1898 - RMSE: 1.0993 - val_loss: 1.1840 - val_RMSE: 1.0999\n",
            "Epoch 36/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1823 - RMSE: 1.1004 - val_loss: 1.1759 - val_RMSE: 1.0998\n",
            "Epoch 37/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1716 - RMSE: 1.0974 - val_loss: 1.1688 - val_RMSE: 1.0996\n",
            "Epoch 38/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1654 - RMSE: 1.0980 - val_loss: 1.1624 - val_RMSE: 1.0995\n",
            "Epoch 39/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1565 - RMSE: 1.0951 - val_loss: 1.1567 - val_RMSE: 1.0993\n",
            "Epoch 40/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1508 - RMSE: 1.0948 - val_loss: 1.1517 - val_RMSE: 1.0992\n",
            "Epoch 41/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1526 - RMSE: 1.1013 - val_loss: 1.1472 - val_RMSE: 1.0991\n",
            "Epoch 42/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1424 - RMSE: 1.0953 - val_loss: 1.1433 - val_RMSE: 1.0990\n",
            "Epoch 43/60\n",
            "293/293 [==============================] - 2s 8ms/step - loss: 1.1422 - RMSE: 1.0989 - val_loss: 1.1397 - val_RMSE: 1.0989\n",
            "Epoch 44/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1388 - RMSE: 1.0988 - val_loss: 1.1366 - val_RMSE: 1.0988\n",
            "Epoch 45/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1327 - RMSE: 1.0957 - val_loss: 1.1338 - val_RMSE: 1.0987\n",
            "Epoch 46/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1294 - RMSE: 1.0951 - val_loss: 1.1313 - val_RMSE: 1.0986\n",
            "Epoch 47/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1252 - RMSE: 1.0932 - val_loss: 1.1291 - val_RMSE: 1.0985\n",
            "Epoch 48/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1248 - RMSE: 1.0948 - val_loss: 1.1271 - val_RMSE: 1.0984\n",
            "Epoch 49/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1263 - RMSE: 1.0981 - val_loss: 1.1254 - val_RMSE: 1.0984\n",
            "Epoch 50/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1242 - RMSE: 1.0977 - val_loss: 1.1238 - val_RMSE: 1.0983\n",
            "Epoch 51/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1166 - RMSE: 1.0915 - val_loss: 1.1224 - val_RMSE: 1.0982\n",
            "Epoch 52/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1228 - RMSE: 1.0990 - val_loss: 1.1212 - val_RMSE: 1.0982\n",
            "Epoch 53/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1189 - RMSE: 1.0963 - val_loss: 1.1201 - val_RMSE: 1.0981\n",
            "Epoch 54/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1193 - RMSE: 1.0977 - val_loss: 1.1191 - val_RMSE: 1.0981\n",
            "Epoch 55/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1182 - RMSE: 1.0975 - val_loss: 1.1183 - val_RMSE: 1.0980\n",
            "Epoch 56/60\n",
            "293/293 [==============================] - 2s 8ms/step - loss: 1.1120 - RMSE: 1.0921 - val_loss: 1.1175 - val_RMSE: 1.0980\n",
            "Epoch 57/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1179 - RMSE: 1.0987 - val_loss: 1.1168 - val_RMSE: 1.0979\n",
            "Epoch 58/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1140 - RMSE: 1.0954 - val_loss: 1.1162 - val_RMSE: 1.0979\n",
            "Epoch 59/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1135 - RMSE: 1.0955 - val_loss: 1.1157 - val_RMSE: 1.0979\n",
            "Epoch 60/60\n",
            "293/293 [==============================] - 2s 7ms/step - loss: 1.1137 - RMSE: 1.0961 - val_loss: 1.1152 - val_RMSE: 1.0978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "GbZd2p8xNKUJ",
        "outputId": "5eca7630-0433-4bbc-eee7-bdddb402b4b7"
      },
      "source": [
        "# Plot RMSE\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['RMSE'], label=\"Train RMSE\")\n",
        "plt.plot(result.history['val_RMSE'], label=\"Test RMSE\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('RMSE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7-aoR9-NKX1",
        "outputId": "0c188c1d-4d5e-400d-9aaf-e95eec71d3f7"
      },
      "source": [
        "# Prediction\n",
        "user_ids = ratings_test.user_id.values[0:3]\n",
        "movie_ids = ratings_test.movie_id.values[0:3]\n",
        "predictions = model.predict([user_ids, movie_ids]) + mu\n",
        "print(\"Actuals: \\n\", ratings_test[0:6])\n",
        "print( )\n",
        "print(\"Predictions: \\n\", predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actuals: \n",
            "        user_id  movie_id  rating\n",
            "53670      345       715       4\n",
            "77110       92       998       2\n",
            "69323      934       195       4\n",
            "85968      586       423       2\n",
            "30243      336       383       1\n",
            "43868      654       678       4\n",
            "\n",
            "Predictions: \n",
            " [[3.5351827]\n",
            " [3.4959416]\n",
            " [3.5932786]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk2-g3zLgcWZ",
        "outputId": "f4b12eee-6d0b-43bd-e2d3-427e81373b52"
      },
      "source": [
        "# RMSE check\n",
        "def RMSE2(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
        "\n",
        "user_ids = ratings_test.user_id.values\n",
        "movie_ids = ratings_test.movie_id.values\n",
        "y_pred = model.predict([user_ids, movie_ids]) + mu\n",
        "y_pred = np.ravel(y_pred, order='C') # 1차원의 array로 바꿔준다.\n",
        "y_true = np.array(ratings_test.rating)\n",
        "\n",
        "RMSE2(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0987217174031805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyUdJ-lZN41b"
      },
      "source": [
        "#### 딥러닝을 적용한 추천 시스템"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVmSIDhZFLCd"
      },
      "source": [
        "# Keras model\n",
        "user = Input(shape=(1, ))                                               # User input\n",
        "item = Input(shape=(1, ))                                               # Item input\n",
        "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)        # (M, 1, K)\n",
        "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)        # (N, 1, K)\n",
        "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)          # User bias term (M, 1, )\n",
        "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)          # Item bias term (N, 1, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lafiHSgOP-sy"
      },
      "source": [
        "# Concatenate layers: 1차원으로 줄인다.\n",
        "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
        "P_embedding = Flatten()(P_embedding)                                    # (K, )\n",
        "Q_embedding = Flatten()(Q_embedding)                                    # (K, )\n",
        "user_bias = Flatten()(user_bias)                                        # (1, )\n",
        "item_bias = Flatten()(item_bias)                                        # (1, )\n",
        "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])     # (2K + 2, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rgrIWBzP-w4",
        "outputId": "2ff6a4d4-5cfb-4894-a516-5d722c366246"
      },
      "source": [
        "# Neural network\n",
        "R = Dense(2048)(R)\n",
        "R = Activation('linear')(R)\n",
        "R = Dense(256)(R)\n",
        "R = Activation('linear')(R)\n",
        "R = Dense(1)(R)\n",
        "\n",
        "model = Model(inputs=[user, item], outputs=R)\n",
        "model.compile(\n",
        "  loss=RMSE,\n",
        "  optimizer=SGD(),\n",
        "  #optimizer=Adamax(),\n",
        "  metrics=[RMSE]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 200)       188800      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 200)       336600      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 1)         944         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 1, 1)         1683        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 200)          0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 200)          0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 1)            0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 1)            0           embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 402)          0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2048)         825344      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 2048)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          524544      activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            257         activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,878,172\n",
            "Trainable params: 1,878,172\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxUBFlkwP-yf",
        "outputId": "1bf1de62-1eea-4882-8a14-d394bfdc4ac5"
      },
      "source": [
        "# Model fitting\n",
        "result = model.fit(\n",
        "  x=[ratings_train.user_id.values, ratings_train.movie_id.values],\n",
        "  y=ratings_train.rating.values - mu,\n",
        "  epochs=65,\n",
        "  batch_size=512,\n",
        "  validation_data=(\n",
        "    [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
        "    ratings_test.rating.values - mu\n",
        "  )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "147/147 [==============================] - 15s 97ms/step - loss: 5.4662 - RMSE: 1.1279 - val_loss: 5.2763 - val_RMSE: 1.1255\n",
            "Epoch 2/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 5.2155 - RMSE: 1.1250 - val_loss: 5.0381 - val_RMSE: 1.1243\n",
            "Epoch 3/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 4.9817 - RMSE: 1.1248 - val_loss: 4.8130 - val_RMSE: 1.1226\n",
            "Epoch 4/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 4.7604 - RMSE: 1.1237 - val_loss: 4.6012 - val_RMSE: 1.1215\n",
            "Epoch 5/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 4.5530 - RMSE: 1.1239 - val_loss: 4.4012 - val_RMSE: 1.1201\n",
            "Epoch 6/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 4.3517 - RMSE: 1.1183 - val_loss: 4.2130 - val_RMSE: 1.1191\n",
            "Epoch 7/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 4.1676 - RMSE: 1.1186 - val_loss: 4.0348 - val_RMSE: 1.1174\n",
            "Epoch 8/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 3.9913 - RMSE: 1.1162 - val_loss: 3.8671 - val_RMSE: 1.1161\n",
            "Epoch 9/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 3.8239 - RMSE: 1.1127 - val_loss: 3.7086 - val_RMSE: 1.1144\n",
            "Epoch 10/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 3.6693 - RMSE: 1.1127 - val_loss: 3.5589 - val_RMSE: 1.1124\n",
            "Epoch 11/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 3.5231 - RMSE: 1.1122 - val_loss: 3.4174 - val_RMSE: 1.1102\n",
            "Epoch 12/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 3.3833 - RMSE: 1.1097 - val_loss: 3.2838 - val_RMSE: 1.1080\n",
            "Epoch 13/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 3.2522 - RMSE: 1.1078 - val_loss: 3.1573 - val_RMSE: 1.1052\n",
            "Epoch 14/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 3.1256 - RMSE: 1.1033 - val_loss: 3.0375 - val_RMSE: 1.1020\n",
            "Epoch 15/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 3.0016 - RMSE: 1.0941 - val_loss: 2.9240 - val_RMSE: 1.0983\n",
            "Epoch 16/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 2.8953 - RMSE: 1.0960 - val_loss: 2.8164 - val_RMSE: 1.0941\n",
            "Epoch 17/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 2.7837 - RMSE: 1.0863 - val_loss: 2.7143 - val_RMSE: 1.0895\n",
            "Epoch 18/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 2.6845 - RMSE: 1.0831 - val_loss: 2.6177 - val_RMSE: 1.0847\n",
            "Epoch 19/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 2.5932 - RMSE: 1.0823 - val_loss: 2.5242 - val_RMSE: 1.0776\n",
            "Epoch 20/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 2.5010 - RMSE: 1.0752 - val_loss: 2.4361 - val_RMSE: 1.0708\n",
            "Epoch 21/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 2.4100 - RMSE: 1.0643 - val_loss: 2.3521 - val_RMSE: 1.0634\n",
            "Epoch 22/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 2.3249 - RMSE: 1.0546 - val_loss: 2.2716 - val_RMSE: 1.0549\n",
            "Epoch 23/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 2.2478 - RMSE: 1.0484 - val_loss: 2.1948 - val_RMSE: 1.0459\n",
            "Epoch 24/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 2.1701 - RMSE: 1.0376 - val_loss: 2.1220 - val_RMSE: 1.0370\n",
            "Epoch 25/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 2.1021 - RMSE: 1.0325 - val_loss: 2.0529 - val_RMSE: 1.0281\n",
            "Epoch 26/65\n",
            "147/147 [==============================] - 14s 98ms/step - loss: 2.0301 - RMSE: 1.0197 - val_loss: 1.9877 - val_RMSE: 1.0195\n",
            "Epoch 27/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 1.9601 - RMSE: 1.0057 - val_loss: 1.9265 - val_RMSE: 1.0118\n",
            "Epoch 28/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 1.8992 - RMSE: 0.9974 - val_loss: 1.8682 - val_RMSE: 1.0039\n",
            "Epoch 29/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 1.8454 - RMSE: 0.9934 - val_loss: 1.8139 - val_RMSE: 0.9972\n",
            "Epoch 30/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 1.7894 - RMSE: 0.9843 - val_loss: 1.7631 - val_RMSE: 0.9914\n",
            "Epoch 31/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.7376 - RMSE: 0.9768 - val_loss: 1.7150 - val_RMSE: 0.9858\n",
            "Epoch 32/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.6838 - RMSE: 0.9649 - val_loss: 1.6708 - val_RMSE: 0.9817\n",
            "Epoch 33/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.6406 - RMSE: 0.9612 - val_loss: 1.6281 - val_RMSE: 0.9770\n",
            "Epoch 34/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.5986 - RMSE: 0.9565 - val_loss: 1.5894 - val_RMSE: 0.9740\n",
            "Epoch 35/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.5646 - RMSE: 0.9579 - val_loss: 1.5516 - val_RMSE: 0.9700\n",
            "Epoch 36/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.5207 - RMSE: 0.9473 - val_loss: 1.5171 - val_RMSE: 0.9674\n",
            "Epoch 37/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.4899 - RMSE: 0.9479 - val_loss: 1.4842 - val_RMSE: 0.9647\n",
            "Epoch 38/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 1.4568 - RMSE: 0.9446 - val_loss: 1.4535 - val_RMSE: 0.9625\n",
            "Epoch 39/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 1.4262 - RMSE: 0.9421 - val_loss: 1.4245 - val_RMSE: 0.9604\n",
            "Epoch 40/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.3982 - RMSE: 0.9406 - val_loss: 1.3997 - val_RMSE: 0.9609\n",
            "Epoch 41/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 1.3706 - RMSE: 0.9379 - val_loss: 1.3717 - val_RMSE: 0.9569\n",
            "Epoch 42/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 1.3428 - RMSE: 0.9337 - val_loss: 1.3474 - val_RMSE: 0.9552\n",
            "Epoch 43/65\n",
            "147/147 [==============================] - 14s 97ms/step - loss: 1.3170 - RMSE: 0.9302 - val_loss: 1.3248 - val_RMSE: 0.9539\n",
            "Epoch 44/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 1.2958 - RMSE: 0.9300 - val_loss: 1.3037 - val_RMSE: 0.9529\n",
            "Epoch 45/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.2795 - RMSE: 0.9336 - val_loss: 1.2845 - val_RMSE: 0.9528\n",
            "Epoch 46/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.2535 - RMSE: 0.9263 - val_loss: 1.2645 - val_RMSE: 0.9506\n",
            "Epoch 47/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 1.2364 - RMSE: 0.9269 - val_loss: 1.2468 - val_RMSE: 0.9499\n",
            "Epoch 48/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.2143 - RMSE: 0.9215 - val_loss: 1.2308 - val_RMSE: 0.9499\n",
            "Epoch 49/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 1.2032 - RMSE: 0.9261 - val_loss: 1.2148 - val_RMSE: 0.9489\n",
            "Epoch 50/65\n",
            "147/147 [==============================] - 14s 96ms/step - loss: 1.1842 - RMSE: 0.9220 - val_loss: 1.2004 - val_RMSE: 0.9488\n",
            "Epoch 51/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.1698 - RMSE: 0.9216 - val_loss: 1.1852 - val_RMSE: 0.9471\n",
            "Epoch 52/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.1570 - RMSE: 0.9221 - val_loss: 1.1722 - val_RMSE: 0.9467\n",
            "Epoch 53/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.1491 - RMSE: 0.9267 - val_loss: 1.1610 - val_RMSE: 0.9475\n",
            "Epoch 54/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.1339 - RMSE: 0.9233 - val_loss: 1.1563 - val_RMSE: 0.9541\n",
            "Epoch 55/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 1.1186 - RMSE: 0.9191 - val_loss: 1.1385 - val_RMSE: 0.9470\n",
            "Epoch 56/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.1089 - RMSE: 0.9200 - val_loss: 1.1268 - val_RMSE: 0.9454\n",
            "Epoch 57/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 1.0981 - RMSE: 0.9192 - val_loss: 1.1180 - val_RMSE: 0.9461\n",
            "Epoch 58/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 1.0895 - RMSE: 0.9199 - val_loss: 1.1079 - val_RMSE: 0.9450\n",
            "Epoch 59/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.0785 - RMSE: 0.9177 - val_loss: 1.0995 - val_RMSE: 0.9451\n",
            "Epoch 60/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.0703 - RMSE: 0.9179 - val_loss: 1.0911 - val_RMSE: 0.9447\n",
            "Epoch 61/65\n",
            "147/147 [==============================] - 14s 94ms/step - loss: 1.0632 - RMSE: 0.9187 - val_loss: 1.0834 - val_RMSE: 0.9446\n",
            "Epoch 62/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.0545 - RMSE: 0.9175 - val_loss: 1.0760 - val_RMSE: 0.9443\n",
            "Epoch 63/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.0491 - RMSE: 0.9191 - val_loss: 1.0704 - val_RMSE: 0.9455\n",
            "Epoch 64/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.0392 - RMSE: 0.9159 - val_loss: 1.0632 - val_RMSE: 0.9446\n",
            "Epoch 65/65\n",
            "147/147 [==============================] - 14s 95ms/step - loss: 1.0302 - RMSE: 0.9131 - val_loss: 1.0561 - val_RMSE: 0.9436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZRULNclSLEN"
      },
      "source": [
        "#### 딥러닝 모델에 변수 추가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBfDb5hqSQoh"
      },
      "source": [
        "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
        "users = users[['user_id', 'occupation']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deb2Rg6-SQs8"
      },
      "source": [
        "# Convert occupation(string to integer)\n",
        "occupation = {}\n",
        "def convert_occ(x):\n",
        "    if x in occupation:\n",
        "        return occupation[x]\n",
        "    else:\n",
        "        occupation[x] = len(occupation)\n",
        "        return occupation[x]\n",
        "users['occupation'] = users['occupation'].apply(convert_occ) \n",
        "# 사용자 데이터의 ocuupation 열을 int로 변환한다.\n",
        "\n",
        "L = len(occupation)\n",
        "train_occ = pd.merge(ratings_train, users, on='user_id')['occupation']\n",
        "test_occ = pd.merge(ratings_test, users, on='user_id')['occupation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOk0UJsYRNha"
      },
      "source": [
        "occ = Input(shape=(1, ))\n",
        "occ_embedding = Embedding(L, 3, embeddings_regularizer=l2())(occ) # 3개의 잠재요인으로 embedding\n",
        "occ_layer = Flatten()(occ_embedding)\n",
        "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias, occ_layer])\n",
        "\n",
        "model = Model(inputs=[user, item, occ], outputs=R)\n",
        "\n",
        "# RMSE가 눈에 띄게 향상되지는 않는다.\n",
        "# 사용자의 평가 패턴과 상관관게가 있는 변수를 추가해야 RMSE가 향상된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7HIuUIWFLV9"
      },
      "source": [
        "### 제 7장 하이브리드 추천 시스템\n",
        "\n",
        ": 복수의 추천 알고리즘을 결합해서 추천하는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B5HX4l8FvCZ"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrrA_oLjFx-0"
      },
      "source": [
        "def RMSE2(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pstqC16FFL1q",
        "outputId": "224be88a-2b1c-406a-843d-98c82b5f432d"
      },
      "source": [
        "# Dummy recommender 0\n",
        "def recommender0(recomm_list):\n",
        "    recommendations = []\n",
        "    for pair in recomm_list:\n",
        "        recommendations.append(random.random() * 4 + 1)\n",
        "    return np.array(recommendations)\n",
        "\n",
        "# Dummy recommender 1\n",
        "def recommender1(recomm_list):\n",
        "    recommendations = []\n",
        "    for pair in recomm_list:\n",
        "        recommendations.append(random.random() * 4 + 1)\n",
        "    return np.array(recommendations)\n",
        "\n",
        "# Hybrid 결과 얻기\n",
        "weight = [0.8, 0.2] # 두 추천엔진의 결합 비중\n",
        "recomm_list = np.array(ratings_test)\n",
        "predictions0 = recommender0(recomm_list)\n",
        "predictions1 = recommender1(recomm_list)\n",
        "predictions = predictions0 * weight[0] + predictions1 * weight[1] #가중 평균\n",
        "RMSE2(recomm_list[:, 2], predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5612758913754048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saJbycVoGhiy"
      },
      "source": [
        "##### CF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
        "\n",
        "rating_matrix = ratings_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
        "\n",
        "# train set 사용자들의 Cosine similarities 계산\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "matrix_dummy = rating_matrix.copy().fillna(0)\n",
        "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
        "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
        "\n",
        "# train 데이터의 user의 rating 평균과 영화의 평점편차 계산 \n",
        "rating_mean = rating_matrix.mean(axis=1)\n",
        "rating_bias = (rating_matrix.T - rating_mean).T\n",
        "\n",
        "def CF_knn_bias(user_id, movie_id, neighbor_size=0):\n",
        "    if movie_id in rating_bias:\n",
        "        sim_scores = user_similarity[user_id]\n",
        "        movie_ratings = rating_bias[movie_id]\n",
        "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
        "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
        "        sim_scores = sim_scores.drop(none_rating_idx)\n",
        "        if neighbor_size == 0:\n",
        "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "            prediction = prediction + rating_mean[user_id]\n",
        "        else:\n",
        "            if len(sim_scores) > 1:\n",
        "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
        "                sim_scores = np.array(sim_scores)\n",
        "                movie_ratings = np.array(movie_ratings)\n",
        "                user_idx = np.argsort(sim_scores)\n",
        "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
        "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
        "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
        "                prediction = prediction + rating_mean[user_id]\n",
        "            else:\n",
        "                prediction = rating_mean[user_id]\n",
        "    else:\n",
        "        prediction = rating_mean[user_id]\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "2dcjam2UFpVS",
        "outputId": "3440dd77-75c1-48e7-8a3d-3b6999079c1b"
      },
      "source": [
        "##### Hybrid 추천 알고리즘\n",
        "\n",
        "def recommender0(recomm_list, mf): # MF\n",
        "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
        "    return recommendations\n",
        "\n",
        "def recommender1(recomm_list, neighbor_size=0): # CF\n",
        "    recommendations = np.array([CF_knn_bias(user, movie, neighbor_size) for (user, movie) in recomm_list])\n",
        "    return recommendations\n",
        "\n",
        "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])\n",
        "predictions0 = recommender0(recomm_list, mf)\n",
        "RMSE2(ratings_test.iloc[:, 2], predictions0)\n",
        "predictions1 = recommender1(recomm_list, 37)\n",
        "RMSE2(ratings_test.iloc[:, 2], predictions1)\n",
        "\n",
        "weight = [0.8, 0.2]\n",
        "predictions = predictions0 * weight[0] + predictions1 * weight[1] # 합친게 미세하게 더 좋게 나온다.\n",
        "RMSE2(ratings_test.iloc[:, 2], predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-a47b1d7099af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpredictions0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mRMSE2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpredictions1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mRMSE2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-a47b1d7099af>\u001b[0m in \u001b[0;36mrecommender1\u001b[0;34m(recomm_list, neighbor_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecommender1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# CF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCF_knn_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecomm_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-a47b1d7099af>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecommender1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# CF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCF_knn_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecomm_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-2afc79db3c86>\u001b[0m in \u001b[0;36mCF_knn_bias\u001b[0;34m(user_id, movie_id, neighbor_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mneighbor_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0msim_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mmovie_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLFnbQocFL4h"
      },
      "source": [
        "# 최적의 가중치 구하기. (0.88:0.12)\n",
        "for i in np.arange(0, 1, 0.01):\n",
        "    weight = [i, 1.0 - i]\n",
        "    predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
        "    print(\"Weights - %.2f : %.2f ; RMSE = %.7f\" % (weight[0], \n",
        "           weight[1], RMSE2(ratings_test.iloc[:, 2], predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}